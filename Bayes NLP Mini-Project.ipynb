{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re as re\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# show all outputs of a cell (such as if df.head() and df.tail() are in the same cell)\n",
    "#default is 'last_expr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text='''\n",
    "Milt, we're gonna need to go ahead and move you downstairs into storage B. We have some new people coming in, and we need all the space we can get. So if you could just go ahead and pack up your stuff and move it down there, that would be terrific, OK?\n",
    "Oh, and remember: next Friday... is Hawaiian shirt day. So, you know, if you want to, go ahead and wear a Hawaiian shirt and jeans.\n",
    "Oh, oh, and I almost forgot. Ahh, I'm also gonna need you to go ahead and come in on Sunday, too...\n",
    "Hello Peter, whats happening? Ummm, I'm gonna need you to go ahead and come in tomorrow. So if you could be here around 9 that would be great, mmmk... oh oh! and I almost forgot ahh, I'm also gonna need you to go ahead and come in on Sunday too, kay. We ahh lost some people this week and ah, we sorta need to play catch up.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My answers to Udacity's Optimal Classifier Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#   In this quiz we will find the maximum likelihood word based on the preceding word\n",
    "#   Fill in the NextWordProbability procedure so that it takes in sample text and a word,\n",
    "#   and returns a dictionary with keys the set of words that come after, whose values are\n",
    "#   the number of times the key comes after that word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'go': 5, 'play': 1}"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Python 3 version\n",
    "def NextWordProbability(sample,word):\n",
    "    import string\n",
    "    table = str.maketrans({key: None for key in string.punctuation})  \n",
    "    text = sample.strip().translate(table).split() #remove punctuation, make lowercase\n",
    "    nextwords={} #make empty dict containing next word: count pairs\n",
    "    for j in range(len(text)):\n",
    "        if text[j]==word:\n",
    "            if text[j+1] in nextwords.keys():#check if next word is in the dict as a key \n",
    "                nextwords[text[j+1]]+=1 #increase value of a key in dict:  dict[key]+=1         \n",
    "            else:\n",
    "                nextwords[text[j+1]]=1 #add next word to dictionary if it does not exist\n",
    "    return nextwords    \n",
    "NextWordProbability(text,'to')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Python 2 version of the above (won't work in this notebook, which is Python 3)\n",
    "def NextWordProb(sample,word):\n",
    "    import string\n",
    "    table = string.maketrans(\"\",\"\") \n",
    "    text = sample.strip().translate(table, string.punctuation).split() \n",
    "    nextwords={}    \n",
    "    for j in range(len(text)):\n",
    "        if text[j]==word:\n",
    "            if text[j+1] in nextwords.keys(): \n",
    "                nextwords[text[j+1]]+=1 \n",
    "            else:\n",
    "                nextwords[text[j+1]]=1          \n",
    "    return nextwords  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#   Bayes Optimal Classifier\n",
    "#\n",
    "#   In this quiz we will compute the optimal label for a second missing word in a row\n",
    "#   based on the possible words that could be in the first blank\n",
    "\n",
    "# TODO: Given a word, collect the relative probabilities of possible following words\n",
    "# from @sample. You may want to import your code from the maximum likelihood exercise.\n",
    "\n",
    "# TODO: Repeat the above process--for each distance beyond 1, evaluate the words that\n",
    "# might come after each word, and combine them weighting by relative probability\n",
    "# into an estimate of what might appear next.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'come'"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def LaterWords(sample,word,distance):\n",
    "    import numpy as np\n",
    "    word1_counts=NextWordProbability(sample,word)\n",
    "    total=sum(word1_counts.values()) \n",
    "    word1probs={}\n",
    "    word2probs={}\n",
    "\n",
    "    for word1, count in list(word1_counts.items()):\n",
    "        word1prob= count/float(total)\n",
    "        word1probs[word1]=word1prob\n",
    "        word2_counts=NextWordProbability(sample,word1)\n",
    "        for word2,count in list(word2_counts.items()):  \n",
    "            word2prob=count*word1prob\n",
    "            if word2 not in word2probs.keys():\n",
    "                word2probs[word2]=word2prob\n",
    "            else:\n",
    "                word2probs[word2]+=word2prob\n",
    "    \n",
    "    if distance==1: \n",
    "        maxProb=max(word1probs.values())\n",
    "        answer=[j for j in word1probs.keys() if word1probs[j]==maxProb ]\n",
    "        if len(answer)==1:        \n",
    "            return ''.join(answer) #returns a string for a one word answer ['hi'] --> 'hi'\n",
    "        else:\n",
    "            return answer\n",
    "    elif distance==2:\n",
    "        maxProb=max(word2probs.values())\n",
    "        answer=[j for j in word2probs.keys() if word2probs[j]==maxProb ]\n",
    "        if len(answer)==1:\n",
    "            return ''.join(answer)\n",
    "        else:\n",
    "            return answer        \n",
    "LaterWords(text,'ahead',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPython 2 version\\nimport string\\ntable = string.maketrans(\"\",\"\") \\ntext = sample.translate(table, string.punctuation)\\n\\nPython 3 version\\nimport string \\ntable = str.maketrans({key: None for key in string.punctuation})\\ntext = sample.translate(table) \\n'"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Removing All Punctuation From a String\n",
    "\n",
    "Python 2 version\n",
    "import string\n",
    "table = string.maketrans(\"\",\"\") \n",
    "text = sample.translate(table, string.punctuation)\n",
    "\n",
    "Python 3 version\n",
    "import string \n",
    "table = str.maketrans({key: None for key in string.punctuation})\n",
    "text = sample.translate(table) \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work related to the above code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dictionary of word:count pairs from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Milt,', \"we're\", 'gonna', 'need', 'to', 'go', 'ahead', 'and', 'move', 'you', 'downstairs', 'into', 'storage', 'B.', 'We', 'have', 'some', 'new', 'people', 'coming', 'in,', 'and', 'we', 'need', 'all', 'the', 'space', 'we', 'can', 'get.', 'So', 'if', 'you', 'could', 'just', 'go', 'ahead', 'and', 'pack', 'up', 'your', 'stuff', 'and', 'move', 'it', 'down', 'there,', 'that', 'would', 'be', 'terrific,', 'OK?\\nOh,', 'and', 'remember:', 'next', 'Friday...', 'is', 'Hawaiian', 'shirt', 'day.', 'So,', 'you', 'know,', 'if', 'you', 'want', 'to,', 'go', 'ahead', 'and', 'wear', 'a', 'Hawaiian', 'shirt', 'and', 'jeans.\\nOh,', 'oh,', 'and', 'I', 'almost', 'forgot.', 'Ahh,', \"I'm\", 'also', 'gonna', 'need', 'you', 'to', 'go', 'ahead', 'and', 'come', 'in', 'on', 'Sunday,', 'too...\\nHello', 'Peter,', 'whats', 'happening?', 'Ummm,', \"I'm\", 'gonna', 'need', 'you', 'to', 'go', 'ahead', 'and', 'come', 'in', 'tomorrow.', 'So', 'if', 'you', 'could', 'be', 'here', 'around', '9', 'that', 'would', 'be', 'great,', 'mmmk...', 'oh', 'oh!', 'and', 'I', 'almost', 'forgot', 'ahh,', \"I'm\", 'also', 'gonna', 'need', 'you', 'to', 'go', 'ahead', 'and', 'come', 'in', 'on', 'Sunday', 'too,', 'kay.', 'We', 'ahh', 'lost', 'some', 'people', 'this', 'week', 'and', 'ah,', 'we', 'sorta', 'need', 'to', 'play', 'catch', 'up.'] \n",
      "\n",
      "['Milt,', \"we're\", 'gonna', 'need', 'to', 'go', 'ahead', 'and', 'move', 'you', 'downstairs', 'into', 'storage', 'B.', 'We', 'have', 'some', 'new', 'people', 'coming', 'in,', 'and', 'we', 'need', 'all', 'the', 'space', 'we', 'can', 'get.', 'So', 'if', 'you', 'could', 'just', 'go', 'ahead', 'and', 'pack', 'up', 'your', 'stuff', 'and', 'move', 'it', 'down', 'there,', 'that', 'would', 'be', 'terrific,', 'OK? Oh,', 'and', 'remember:', 'next', 'Friday...', 'is', 'Hawaiian', 'shirt', 'day.', 'So,', 'you', 'know,', 'if', 'you', 'want', 'to,', 'go', 'ahead', 'and', 'wear', 'a', 'Hawaiian', 'shirt', 'and', 'jeans. Oh,', 'oh,', 'and', 'I', 'almost', 'forgot.', 'Ahh,', \"I'm\", 'also', 'gonna', 'need', 'you', 'to', 'go', 'ahead', 'and', 'come', 'in', 'on', 'Sunday,', 'too... Hello', 'Peter,', 'whats', 'happening?', 'Ummm,', \"I'm\", 'gonna', 'need', 'you', 'to', 'go', 'ahead', 'and', 'come', 'in', 'tomorrow.', 'So', 'if', 'you', 'could', 'be', 'here', 'around', '9', 'that', 'would', 'be', 'great,', 'mmmk...', 'oh', 'oh!', 'and', 'I', 'almost', 'forgot', 'ahh,', \"I'm\", 'also', 'gonna', 'need', 'you', 'to', 'go', 'ahead', 'and', 'come', 'in', 'on', 'Sunday', 'too,', 'kay.', 'We', 'ahh', 'lost', 'some', 'people', 'this', 'week', 'and', 'ah,', 'we', 'sorta', 'need', 'to', 'play', 'catch', 'up.'] \n",
      "\n",
      "['Milt,', \"we're\", 'gonna', 'need', 'to', 'go', 'ahead', 'and', 'move', 'you', 'downstairs', 'into', 'storage', 'B', 'We', 'have', 'some', 'new', 'people', 'coming', 'in,', 'and', 'we', 'need', 'all', 'the', 'space', 'we', 'can', 'get', 'So', 'if', 'you', 'could', 'just', 'go', 'ahead', 'and', 'pack', 'up', 'your', 'stuff', 'and', 'move', 'it', 'down', 'there,', 'that', 'would', 'be', 'terrific,', 'OK? Oh,', 'and', 'remember:', 'next', 'Friday', 'is', 'Hawaiian', 'shirt', 'day', 'So,', 'you', 'know,', 'if', 'you', 'want', 'to,', 'go', 'ahead', 'and', 'wear', 'a', 'Hawaiian', 'shirt', 'and', 'jeans. Oh,', 'oh,', 'and', 'I', 'almost', 'forgot', 'Ahh,', \"I'm\", 'also', 'gonna', 'need', 'you', 'to', 'go', 'ahead', 'and', 'come', 'in', 'on', 'Sunday,', 'too... Hello', 'Peter,', 'whats', 'happening?', 'Ummm,', \"I'm\", 'gonna', 'need', 'you', 'to', 'go', 'ahead', 'and', 'come', 'in', 'tomorrow', 'So', 'if', 'you', 'could', 'be', 'here', 'around', '9', 'that', 'would', 'be', 'great,', 'mmmk', 'oh', 'oh!', 'and', 'I', 'almost', 'forgot', 'ahh,', \"I'm\", 'also', 'gonna', 'need', 'you', 'to', 'go', 'ahead', 'and', 'come', 'in', 'on', 'Sunday', 'too,', 'kay', 'We', 'ahh', 'lost', 'some', 'people', 'this', 'week', 'and', 'ah,', 'we', 'sorta', 'need', 'to', 'play', 'catch', 'up']\n"
     ]
    }
   ],
   "source": [
    "text_list=text.split(' ') #split text by spaces\n",
    "text_list=[x.strip('\\n') for x in text.split(' ')] #strip away newline characters\n",
    "print(text_list,'\\n') #notice there are \\n's in the middle of certain text elements still\n",
    "text_list=[x.replace('\\n', ' ') for x in text_list] #replace \\n in middle of texts with space\n",
    "print (text_list, '\\n') #notice there are a couple words with '...' after them, let's strip it\n",
    "text_list=[x.strip('.') for x in text_list]\n",
    "print(text_list) #tadahh!  we've got a list of each word without all of the garbage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Milt,': 1, \"we're\": 1, 'gonna': 4, 'need': 6, 'to': 5, 'go': 6, 'ahead': 6, 'and': 13, 'move': 2, 'you': 8, 'downstairs': 1, 'into': 1, 'storage': 1, 'B': 1, 'We': 2, 'have': 1, 'some': 2, 'new': 1, 'people': 2, 'coming': 1, 'in,': 1, 'we': 3, 'all': 1, 'the': 1, 'space': 1, 'can': 1, 'get': 1, 'So': 2, 'if': 3, 'could': 2, 'just': 1, 'pack': 1, 'up': 2, 'your': 1, 'stuff': 1, 'it': 1, 'down': 1, 'there,': 1, 'that': 2, 'would': 2, 'be': 3, 'terrific,': 1, 'OK? Oh,': 1, 'remember:': 1, 'next': 1, 'Friday': 1, 'is': 1, 'Hawaiian': 2, 'shirt': 2, 'day': 1, 'So,': 1, 'know,': 1, 'want': 1, 'to,': 1, 'wear': 1, 'a': 1, 'jeans. Oh,': 1, 'oh,': 1, 'I': 2, 'almost': 2, 'forgot': 2, 'Ahh,': 1, \"I'm\": 3, 'also': 2, 'come': 3, 'in': 3, 'on': 2, 'Sunday,': 1, 'too... Hello': 1, 'Peter,': 1, 'whats': 1, 'happening?': 1, 'Ummm,': 1, 'tomorrow': 1, 'here': 1, 'around': 1, '9': 1, 'great,': 1, 'mmmk': 1, 'oh': 1, 'oh!': 1, 'ahh,': 1, 'Sunday': 1, 'too,': 1, 'kay': 1, 'ahh': 1, 'lost': 1, 'this': 1, 'week': 1, 'ah,': 1, 'sorta': 1, 'play': 1, 'catch': 1}\n"
     ]
    }
   ],
   "source": [
    "#Counter returns word frequencies for list of words\n",
    "def Counts(text):\n",
    "    text_list=text.split(' ') #split text by spaces\n",
    "    text_list=[x.strip('\\n') for x in text.split(' ')] #strip away newline characters\n",
    "    text_list=[x.replace('\\n', ' ') for x in text_list] #replace \\n's in middle with a space\n",
    "    text_list=[x.strip('.') for x in text_list] #strip periods at end of strings         \n",
    "    #return counter object showing word:count tuples \n",
    "    text_counts=([(x,text_list.count(x)) for x in text_list])\n",
    "    #list.count(x) returns the number of times x is in the list.  We return tuples (x,count).  \n",
    "    return dict(text_counts) #return dictionary of key:value pairs of word:counts\n",
    "                             #the dictionary wipes out duplicate keys\n",
    "print(Counts(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "text_counts=dict(Counter(text_list))\n",
    "#the above is an alternative way of coming up with counts.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirty work to figure out an answer to Udacity's Optimal Classifier Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return a dictionary of key:value pairs for word1 such that (key=word j that comes after word1 : value= # of times word j comes after word1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gonna need', 'gonna need', 'gonna need', 'gonna need']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[[' need'], [' need'], [' need'], [' need']]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['need', 'need', 'need', 'need']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'need': 4}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word1='gonna'\n",
    "l=re.findall(word1+'[\\s][\\w]*',text) #* return all alphanum chars after the space after word1\n",
    "l\n",
    "c=[' '.join(re.findall('[\\s][\\w]*',x)).strip(' ') for x in l] #return strs of just \" need\" and strip whitespace  \n",
    "[re.findall('[\\s][\\w]*',x) for x in l] #w/o join, lists are returned.  join returns all list elements as a combined str\n",
    "c\n",
    "dict([(x,c.count(x)) for x in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gonna need', 'gonna need', 'gonna need', 'gonna need']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['need', 'need', 'need', 'need']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'need': 4}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alternatively,\n",
    "word1='gonna'\n",
    "l=re.findall(word1+'[\\s][\\w]*',text) #* return all alphanum chars after the space after word1\n",
    "l\n",
    "s=[x.replace(word1+' ','') for x in l] \n",
    "s\n",
    "dict([(x,s.count(x)) for x in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'move': 2, 'we': 1, 'pack': 1, 'remember': 1, 'wear': 1, 'jeans': 1, 'I': 2, 'come': 3, 'ah': 1}\n"
     ]
    }
   ],
   "source": [
    "def NextWordCount(text,word):\n",
    "    import re as re\n",
    "    r=re.findall(word+'[\\s][\\w]*',text) \n",
    "    s=[x.replace(word+' ','') for x in r] \n",
    "    counts=dict([(x,s.count(x)) for x in s])\n",
    "    return counts\n",
    "print(NextWordCount(text,'and'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the word with the max(prob) of coming after word1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('move', 2), ('we', 1), ('pack', 1), ('remember', 1), ('wear', 1), ('jeans', 1), ('I', 2), ('come', 3), ('ah', 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.15384615,  0.07692308,  0.07692308,  0.07692308,  0.07692308,\n",
       "        0.07692308,  0.15384615,  0.23076923,  0.07692308])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total=sum(NextWordCount(text,'and').values()) #total number of words after 'and'\n",
    "tuples=list(NextWordCount(text,'and').items()) #make list of tuples of (wordj,freq)\n",
    "print(tuples)\n",
    "probs=np.array(list(NextWordCount(text,'and').values()))/float(total)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('move', 0.15384615384615385), ('we', 0.07692307692307693), ('pack', 0.07692307692307693), ('remember', 0.07692307692307693), ('wear', 0.07692307692307693), ('jeans', 0.07692307692307693), ('I', 0.15384615384615385), ('come', 0.23076923076923078), ('ah', 0.07692307692307693)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('come', 0.23076923076923078)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get word(s) with max probability of following word1\n",
    "probs=[]\n",
    "for x in tuples:\n",
    "    probs.append((x[0],x[1]/float(total)))\n",
    "print(probs)\n",
    "maximum=[('',0)]\n",
    "for x in probs:\n",
    "    if x[1]==maximum[0][1]:\n",
    "        maximum.append(x)\n",
    "    elif x[1]>maximum[0][1]:\n",
    "        maximum=[x]\n",
    "    else:\n",
    "        continue\n",
    "maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def NextWordProbability(NextWordCount):\n",
    "    def probs(text,word):\n",
    "        total=sum(NextWordCount(text,word).values())    \n",
    "        tuples=list(NextWordCount(text,word).items())\n",
    "        probs=[]\n",
    "        for x in tuples:\n",
    "            probs.append((x[0],x[1]/float(total)))\n",
    "        maximum=[('',0)]\n",
    "        for x in probs:\n",
    "            if x[1]==maximum[0][1]:\n",
    "                maximum.append(x)\n",
    "            elif x[1]>maximum[0][1]:\n",
    "                maximum=[x]\n",
    "            else:\n",
    "                continue\n",
    "        return maximum\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('come', 0.23076923076923078)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob=NextWordProbability(NextWordCount)\n",
    "prob(text,'and')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the label for the second missing word after word1 (assuming we have a corrupt text file that has two words missing after word 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let <br>\n",
    "w2 = the second missing word after word1 (w2 represents a value for the second missing word, 'hi') <br>\n",
    "w1 = the first missing word after word1 (w1 represents a value for the first missing word, like 'and')<br>\n",
    "w0 = the word occurring in the corrupted sentence (the given)<br>\n",
    "We want to find p(w2|w0), the probability of observing word 2 = \"c\" two words after the given word, w0.<br>\n",
    "We decompose p(w2|w0) into marginal probabilities by summing its likelihoods when word1 takes on different values. w1j is word1 taking its jth possible value.  <br>\n",
    "**p(w2| w0) = p(w2, w1a| w0) + p(w2, w1b| w0) + ... + p(w2, w1z| w0)** <br> \n",
    "Since we already have p(w1j|w0), we'd like to make use of this in the formula p(w2|w0), so that we rewrite the formula: <br>\n",
    "\n",
    "p(w2,w1j|w0) = p(w2| w1j, w0) p(w1j| w0) <br>\n",
    "p(a,b|c) = p(a|b,c) p(b|c) **<br>\n",
    "\n",
    "p(w2|w0) = p(w2|w1a,w0) p(w1a|w0) + ... + p(w2|wja,w0) p(wja|w0)\n",
    "\n",
    "**Formula \\*\\* is derived below ** :<br>\n",
    "p(a,b,c)/p(c) = p(a|b,c) p(b|c) p(c) / p(c)<br>\n",
    "p(a,b,c)/p(c) = p(a|b,c) p(b,c) / p(c)<br>\n",
    "p(a,b|c) = p(a|b,c)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "For each possible 2nd word after word 0,  \n",
    "produce probability of that word by summing its marginal probabilities across every word1 that it can come after\n",
    "   marginal prob j = p(w2|w1j,w0)p(w1j|w0)=(# of w2,w1j / # w1) x p(w1j)\n",
    "   sum(marginal prob j) across all j word1's\n",
    "   \n",
    "Produce list of all word2's\n",
    "Loop through word 2's, and for each,\n",
    "1) Loop through word1's and if word1 has word2j following it\n",
    "    count # of word2 after word1 and count # of word 1's\n",
    "    calculate p(w2|w1j,w0) = (#w2,w1j / #w1j)\n",
    "    calculate p(w2,w1j|w0) = above x p(w1j|w0)\n",
    "2) after looping through all word1's calculating marginal probabilities of w2, sum all marginal probabilities\n",
    "\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Produce list of word1's where word0 is 'and'\n",
    "Create list of x[j] = jth word1, x[j][1], dictionary of word2 and their counts for word1\n",
    "Output [(word1, count), [(word2j, word2j count)]]\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('go', 4), [('ahead', 6)]),\n",
       " (('storage', 1), [('B', 1)]),\n",
       " (('play', 1), [('catch', 1)])]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=[] \n",
    "word1_counts=list(NextWordCount(text,'to').items()) \n",
    "for x in word1_counts:\n",
    "    words.append(((x[0],x[1]), list(NextWordCount(text,x[0]).items())))\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\np(w2|w0,w1)p(w1|w0)\\n(# of w2,w1)/(# of w1)   x (# of w1,w0) / (# of w0)\\n(# of times word 2 shows up after word0) / (# of word 2,word0's)\\n\""
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['need', 'Hawaiian']"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[5, 1]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('need', 0.83333333333333337), ('Hawaiian', 0.16666666666666666)]\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "p(w2|w0,w1)p(w1|w0)\n",
    "(# of w2,w1)/(# of w1)   x (# of w1,w0) / (# of w0)\n",
    "(# of times word 2 shows up after word0) / (# of word 2,word0's)\n",
    "'''\n",
    "word2_counts=[]\n",
    "word2_words=[]\n",
    "for w1_w2s in words:\n",
    "    for w2 in w1_w2s[1]: \n",
    "            if w2[0] not in word2_words:  \n",
    "                word2_words.append(w2[0])\n",
    "                word2_counts.append((w2[1]))\n",
    "            elif w2[0] in word2_words:\n",
    "                index=word2_words.index(w2[0])\n",
    "                word2_counts[index]+=w2[1]\n",
    "word2_words\n",
    "word2_counts\n",
    "total_word2s=sum(word2_counts)\n",
    "word2_probs=np.array(word2_counts)/float(total_word2s)\n",
    "word2_word_probs=list(zip(word2_words,word2_probs))\n",
    "print(word2_word_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIRST ATTEMPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LaterWords(sample,word,distance=1): \n",
    "    import numpy as np\n",
    "   \n",
    "    def NextWordCount(sample,word):\n",
    "            import re as re\n",
    "            r=re.findall(word+'[\\s][\\w]*',sample) \n",
    "            s=[x.replace(word+' ','') for x in r] \n",
    "            counts=dict([(x,s.count(x)) for x in s])\n",
    "            return counts\n",
    "        \n",
    "    #Return word1(s) with max probability\n",
    "    if distance==1:        \n",
    "        def NextWordProbability(NextWordCount):\n",
    "            def probs(sample,word):\n",
    "                total=sum(NextWordCount(sample,word).values())    \n",
    "                tuples=list(NextWordCount(sample,word).items())\n",
    "                probs=[]\n",
    "                for x in tuples:\n",
    "                    probs.append((x[0],x[1]/float(total)))\n",
    "                maximum=[('',0)]\n",
    "                for x in probs:\n",
    "                    if x[1]==maximum[0][1]:\n",
    "                        maximum.append(x)\n",
    "                    elif x[1]>maximum[0][1]:\n",
    "                        maximum=[x]\n",
    "                    else:\n",
    "                        continue\n",
    "                return maximum\n",
    "            return probs\n",
    "        \n",
    "        maximum1=[]\n",
    "        for x in NextWordProbability(NextWordCount)(sample,word):\n",
    "            maximum1.append(x[0])\n",
    "            \n",
    "        return ' '.join(maximum1)\n",
    "            \n",
    "            \n",
    "    #Return word2(s) with max probability\n",
    "    elif distance==2:\n",
    "        words=[] \n",
    "        word2_counts=[]\n",
    "        word2_words=[]\n",
    "    \n",
    "        #create words, which contains word1 counts and word2 counts for each word2 in word1\n",
    "        word1_counts=list(NextWordCount(sample,word).items()) \n",
    "        for x in word1_counts:\n",
    "            words.append(((x[0],x[1]), list(NextWordCount(sample,x[0]).items())))\n",
    "        \n",
    "        #create word2 counts\n",
    "        for w1_w2s in words:\n",
    "            for w2 in w1_w2s[1]: \n",
    "                if w2[0] not in word2_words:  \n",
    "                    word2_words.append(w2[0])\n",
    "                    word2_counts.append((w2[1]))\n",
    "                elif w2[0] in word2_words:\n",
    "                    index=word2_words.index(w2[0])\n",
    "                    word2_counts[index]+=w2[1]\n",
    "     \n",
    "        #create word2 probabilities and find max probability\n",
    "        total_word2s=sum(word2_counts)\n",
    "        word2_probs=np.array(word2_counts)/float(total_word2s)\n",
    "        word2_word_probs=list(zip(word2_words,word2_probs))\n",
    "        maximum2=[('',0)]\n",
    "        maximum2_words=[]\n",
    "        \n",
    "        for x in word2_word_probs:\n",
    "            if x[1]==maximum2[0][1]:\n",
    "                maximum2.append(x)\n",
    "            elif x[1]>maximum2[0][1]:\n",
    "                maximum2=[x]\n",
    "            else:\n",
    "                continue\n",
    "        for x in maximum2:\n",
    "            maximum2_words.append(x[0])\n",
    "            \n",
    "        return ' '.join(maximum2_words)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
